{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.0"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dwiahmad/02-tensor-operations?scriptVersionId=289848047\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# 02 - Tensor Operations\n\n**PyTorch Course by Dwi Ahmad Dzulhijjah**\n\n---\n\n## üìå Learning Objectives\n\nPada notebook ini, kamu akan belajar:\n- Operasi aritmatika pada tensor\n- Indexing dan slicing\n- Reshaping tensor\n- Matrix operations","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Operasi Aritmatika","metadata":{}},{"cell_type":"code","source":"a = torch.tensor([1, 2, 3, 4])\nb = torch.tensor([5, 6, 7, 8])\n\nprint(f\"a + b = {a + b}\")\nprint(f\"a - b = {a - b}\")\nprint(f\"a * b = {a * b}\")\nprint(f\"a / b = {a / b}\")\nprint(f\"a ** 2 = {a ** 2}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Indexing dan Slicing","metadata":{}},{"cell_type":"code","source":"tensor = torch.arange(1, 13).reshape(3, 4)\nprint(\"Original:\\n\", tensor)\n\nprint(f\"\\nElement [0, 0]: {tensor[0, 0]}\")\nprint(f\"First row: {tensor[0]}\")\nprint(f\"First column: {tensor[:, 0]}\")\nprint(f\"Submatrix:\\n{tensor[0:2, 1:3]}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Reshaping","metadata":{}},{"cell_type":"code","source":"tensor = torch.arange(12)\nprint(f\"Original shape: {tensor.shape}\")\n\n# Reshape\nreshaped = tensor.reshape(3, 4)\nprint(f\"Reshaped (3, 4):\\n{reshaped}\")\n\n# View (shares memory)\nviewed = tensor.view(2, 6)\nprint(f\"\\nViewed (2, 6):\\n{viewed}\")\n\n# Flatten\nflattened = reshaped.flatten()\nprint(f\"\\nFlattened: {flattened}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Squeeze dan Unsqueeze\ntensor = torch.rand(1, 3, 1, 4)\nprint(f\"Original: {tensor.shape}\")\n\nsqueezed = tensor.squeeze()\nprint(f\"Squeezed: {squeezed.shape}\")\n\nunsqueezed = squeezed.unsqueeze(0)\nprint(f\"Unsqueezed: {unsqueezed.shape}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Matrix Operations","metadata":{}},{"cell_type":"code","source":"A = torch.rand(3, 4)\nB = torch.rand(4, 5)\n\n# Matrix multiplication\nC = torch.matmul(A, B)  # or A @ B\nprint(f\"A shape: {A.shape}\")\nprint(f\"B shape: {B.shape}\")\nprint(f\"C = A @ B shape: {C.shape}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Transpose\ntensor = torch.rand(2, 3)\nprint(f\"Original: {tensor.shape}\")\nprint(f\"Transposed: {tensor.T.shape}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Aggregation Functions","metadata":{}},{"cell_type":"code","source":"tensor = torch.rand(3, 4)\nprint(\"Tensor:\\n\", tensor)\n\nprint(f\"\\nSum: {tensor.sum()}\")\nprint(f\"Mean: {tensor.mean()}\")\nprint(f\"Max: {tensor.max()}\")\nprint(f\"Min: {tensor.min()}\")\nprint(f\"Argmax: {tensor.argmax()}\")\n\n# Along dimension\nprint(f\"\\nSum along dim=0: {tensor.sum(dim=0)}\")\nprint(f\"Sum along dim=1: {tensor.sum(dim=1)}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìù Exercises\n\n1. Buat 2 tensor 3x3 dan lakukan matrix multiplication\n2. Reshape tensor 1D dengan 24 elemen menjadi bentuk (2, 3, 4)\n3. Hitung mean dari setiap kolom pada tensor 4x5","metadata":{}},{"cell_type":"code","source":"# Your code here\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n**Next:** [03 - Autograd](03_autograd.ipynb)","metadata":{}}]}